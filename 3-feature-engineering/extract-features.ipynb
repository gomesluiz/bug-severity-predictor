{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug Severity Predictor for Mozilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I'll build a severity predictor for the [Mozilla project](https://www.mozilla.org/en-US/) that uses the description of a bug report stored a in [Bugzilla Tracking System](https://bugzilla.mozilla.org/home) to predict its severity. \n",
    "\n",
    "The severity in the Mozilla project indicates how severe the problem is – from blocker (\"application unusable\") to trivial (\"minor cosmetic issue\"). Also, this field can be used to indicate whether a bug is an enhancement request. In my project, I have considered five severity levels: **trivial(0)**, **minor(1)**, **major(2)**, **critical(3)**, and **blocker(4)**. I have ignored the default severity level (often **\"normal\"**) because this level is considered as a choice made by users when they are not sure about the correct severity level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step in machine learning workflow will extract features from raw data via data mining techniques.These features can be used to improve the performance of \n",
    "machine learning algorithms. In my project, I'll use the [Pre-training of Deep Bidirectional Transformers for Language Understanding (BERT)](https://arxiv.org/abs/1810.04805) to extract feature for my predicting model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below declares the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYdhYgbFAMnz",
    "outputId": "17592e68-f7c4-4813-b4d2-80793f7a94b0"
   },
   "outputs": [],
   "source": [
    "import logging \n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from feature_engineering import extract_features_fn\n",
    "#from google.colab import drive \n",
    "#drive.mount('/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below load the cleaned bug reports dataset. This dataset has the following attributes:\n",
    "\n",
    "| **Attribute** | **Description** |\n",
    "| :------------ | :-------------- |\n",
    "| long_description |  The description of a report written when the bug report was opened. |\n",
    "| severity_code | The target label that represents the bug severity level.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cXw3-GAtAMoq"
   },
   "outputs": [],
   "source": [
    "batch_len=1000 # to preserve computational resources only 1000 bug reports were used.\n",
    "reports_input_path = os.path.join('..', 'data', 'clean')\n",
    "reports_data = pd.read_csv(os.path.join(reports_input_path, 'mozilla_bug_report_data.csv'))[:batch_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8gKQ7nfnAMow",
    "outputId": "d63a7f9c-e3b8-4433-e6e0-7f425dd2b127"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_description</th>\n",
       "      <th>severity_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is broken many users can t enter bugs on it p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adding support for custom headers and cookie n...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the patch in bug regressed the fix from bug th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from bugzilla helper user agent mozilla x u li...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i found it odd that relogin cgi didn t clear o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    long_description  severity_code\n",
       "0   is broken many users can t enter bugs on it p...              4\n",
       "1  adding support for custom headers and cookie n...              4\n",
       "2  the patch in bug regressed the fix from bug th...              2\n",
       "3  from bugzilla helper user agent mozilla x u li...              2\n",
       "4  i found it odd that relogin cgi didn t clear o...              1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These cells below extracts features from the dataset to be inputed in the model to predict the bug severity level. I've choose the [DistilBERT](https://medium.com/huggingface/distilbert-8cf3380435b5) as the feature extractor of my project.\n",
    "\n",
    "> \"DistilBERT processes the sentence and passes along some information it extracted from it on to the > next model. DistilBERT is a smaller version of [BERT](https://arxiv.org/abs/1810.04805) developed and open sourced by the \n",
    "> team at HuggingFace. It’s a lighter and faster version of BERT that roughly matches its\n",
    "> performance.\" (Jay Alammar in [A Visual Guide to Using BERT for the First Time](https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LbeFefCoAMo8"
   },
   "outputs": [],
   "source": [
    "# import pre-trained DistilBERT model and tokenizer\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, \n",
    "                                                    ppb.DistilBertTokenizer, \n",
    "                                                    'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QLLEQtdbAMpA"
   },
   "outputs": [],
   "source": [
    "# load pretrained weigths in model/tokenizer objects.\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model     = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features using the function extract_features_fn from feature_engineering \n",
    "# local package.\n",
    "features, labels  = extract_features_fn(reports_data, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eOZA7rM5AMpi"
   },
   "outputs": [],
   "source": [
    "# split features and labels in training and testing sets.\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=.25\n",
    "                                                                            , stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the extracted features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below saves the training and testing sets in disk for training and testing steps\n",
    "machine workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-f29jseiAMpk"
   },
   "outputs": [],
   "source": [
    "#processed_output_path = os.path.join('/','drive', 'My Drive', 'data', 'processed')\n",
    "processed_output_path = os.path.join('..','data', 'processed')\n",
    "if not os.path.exists(processed_output_path):\n",
    "    os.makedirs(processed_output_path)\n",
    "    \n",
    "torch.save(np.column_stack((train_features, train_labels)), \n",
    "        os.path.join(processed_output_path, 'mozilla_bug_report_train_data.pt'))\n",
    "torch.save(np.column_stack((test_features, test_labels)), \n",
    "        os.path.join(processed_output_path, 'mozilla_bug_report_test_data.pt'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "extract-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
