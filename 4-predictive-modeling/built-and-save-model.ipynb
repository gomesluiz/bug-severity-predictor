{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdLIqBsPTDBc",
        "outputId": "6d175491-b252-4ed9-cdb6-8dae7a9659ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os \n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch \n",
        "import xgboost as xgb \n",
        "\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, log_loss\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3wtCPGYTDCC"
      },
      "source": [
        "def load_data(file_path):\n",
        "    \"\"\"Load pytorch tensor data from file\n",
        "\n",
        "    Args:\n",
        "        filepath (str): a full filename path.\n",
        "\n",
        "    Returns:\n",
        "        X (array): a numpy array of features.\n",
        "        y (array): a numpy array of labels.\n",
        "    \"\"\"\n",
        "    tensors = torch.load(file_path)\n",
        "    X = tensors[:, :-1].copy()\n",
        "    y = tensors[:, -1].copy().astype(int)\n",
        "\n",
        "    return (X, y)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_YrS8MZTDCI"
      },
      "source": [
        "tensors_input_path = os.path.join('/', 'drive', 'My Drive', 'data', 'processed')\n",
        "X_train, y_train   = load_data(os.path.join(tensors_input_path, 'mozilla_bug_report_train_data.pt'))\n",
        "X_test, y_test   = load_data(os.path.join(tensors_input_path, 'mozilla_bug_report_test_data.pt'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xkbtD1HTDCN"
      },
      "source": [
        "def score(params):\n",
        "    print(\"Training with params : \")\n",
        "    print(params)\n",
        "    \n",
        "    num_round = int(params['n_estimators'])\n",
        "    del params['n_estimators']\n",
        "   \n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dvalid = xgb.DMatrix(X_test, label=y_test)\n",
        "    model  = xgb.train(params, dtrain, num_round)\n",
        "    \n",
        "    predictions = model.predict(dvalid).reshape((X_test.shape[0], 5))\n",
        "    \n",
        "    score = log_loss(y_test, predictions)\n",
        "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
        "    return {'loss': score, 'status': STATUS_OK}\n",
        "\n",
        "def optimize(trials):\n",
        "    space = {\n",
        "             'n_estimators' : hp.quniform('n_estimators', 100, 1000, 1),\n",
        "             'eta' : hp.quniform('eta', 0.025, 0.5, 0.025),\n",
        "             'max_depth' : hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
        "             'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n",
        "             'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
        "             'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n",
        "             'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
        "             'num_class' : 5,\n",
        "             'eval_metric': 'mlogloss',\n",
        "             'objective': 'multi:softprob',\n",
        "             'nthread' : 6,\n",
        "             'silent' : 1\n",
        "             }\n",
        "\n",
        "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=10)\n",
        "\n",
        "    print(best)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByIGD1xXTDCS",
        "outputId": "f704560a-9a1a-4350-d3fa-db9c75998924",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "trials = Trials()\n",
        "\n",
        "optimize(trials)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with params : \n",
            "{'colsample_bytree': 0.55, 'eta': 0.375, 'eval_metric': 'mlogloss', 'gamma': 0.8, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 925.0, 'nthread': 6, 'num_class': 5, 'objective': 'multi:softprob', 'silent': 1, 'subsample': 0.9500000000000001}\n",
            "\tScore 1.540851269364357\n",
            "\n",
            "\n",
            "Training with params : \n",
            "{'colsample_bytree': 0.6000000000000001, 'eta': 0.17500000000000002, 'eval_metric': 'mlogloss', 'gamma': 0.75, 'max_depth': 5, 'min_child_weight': 5.0, 'n_estimators': 797.0, 'nthread': 6, 'num_class': 5, 'objective': 'multi:softprob', 'silent': 1, 'subsample': 0.8500000000000001}\n",
            "\tScore 1.4581984588950871\n",
            "\n",
            "\n",
            "Training with params : \n",
            "{'colsample_bytree': 0.8, 'eta': 0.47500000000000003, 'eval_metric': 'mlogloss', 'gamma': 0.55, 'max_depth': 6, 'min_child_weight': 4.0, 'n_estimators': 270.0, 'nthread': 6, 'num_class': 5, 'objective': 'multi:softprob', 'silent': 1, 'subsample': 0.8500000000000001}\n",
            "\tScore 1.5711855987086891\n",
            "\n",
            "\n",
            "Training with params : \n",
            "{'colsample_bytree': 0.75, 'eta': 0.17500000000000002, 'eval_metric': 'mlogloss', 'gamma': 0.55, 'max_depth': 2, 'min_child_weight': 6.0, 'n_estimators': 223.0, 'nthread': 6, 'num_class': 5, 'objective': 'multi:softprob', 'silent': 1, 'subsample': 0.8500000000000001}\n",
            "\tScore 1.521047233209014\n",
            "\n",
            "\n",
            "Training with params : \n",
            "{'colsample_bytree': 0.75, 'eta': 0.15000000000000002, 'eval_metric': 'mlogloss', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 169.0, 'nthread': 6, 'num_class': 5, 'objective': 'multi:softprob', 'silent': 1, 'subsample': 0.65}\n",
            "\tScore 1.470464977324009\n",
            "\n",
            "\n",
            "Training with params : \n",
            "{'colsample_bytree': 0.9500000000000001, 'eta': 0.4, 'eval_metric': 'mlogloss', 'gamma': 1.0, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 767.0, 'nthread': 6, 'num_class': 5, 'objective': 'multi:softprob', 'silent': 1, 'subsample': 0.6000000000000001}\n",
            "\tScore 1.6355465815663337\n",
            "\n",
            "\n",
            "Training with params : \n",
            "{'colsample_bytree': 0.65, 'eta': 0.07500000000000001, 'eval_metric': 'mlogloss', 'gamma': 0.55, 'max_depth': 7, 'min_child_weight': 6.0, 'n_estimators': 581.0, 'nthread': 6, 'num_class': 5, 'objective': 'multi:softprob', 'silent': 1, 'subsample': 0.8500000000000001}\n",
            "\tScore 1.4320762475430966\n",
            "\n",
            "\n",
            "Training with params : \n",
            "{'colsample_bytree': 0.9500000000000001, 'eta': 0.225, 'eval_metric': 'mlogloss', 'gamma': 0.8500000000000001, 'max_depth': 5, 'min_child_weight': 1.0, 'n_estimators': 824.0, 'nthread': 6, 'num_class': 5, 'objective': 'multi:softprob', 'silent': 1, 'subsample': 0.8500000000000001}\n",
            "\tScore 1.4575371583104133\n",
            "\n",
            "\n",
            "Training with params : \n",
            "{'colsample_bytree': 0.6000000000000001, 'eta': 0.35000000000000003, 'eval_metric': 'mlogloss', 'gamma': 0.8500000000000001, 'max_depth': 2, 'min_child_weight': 3.0, 'n_estimators': 958.0, 'nthread': 6, 'num_class': 5, 'objective': 'multi:softprob', 'silent': 1, 'subsample': 0.75}\n",
            "\tScore 1.6137569116204977\n",
            "\n",
            "\n",
            "Training with params : \n",
            "{'colsample_bytree': 0.55, 'eta': 0.35000000000000003, 'eval_metric': 'mlogloss', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 365.0, 'nthread': 6, 'num_class': 5, 'objective': 'multi:softprob', 'silent': 1, 'subsample': 0.7000000000000001}\n",
            "\tScore 1.6810551489442587\n",
            "\n",
            "\n",
            "100%|██████████| 10/10 [12:36<00:00, 75.67s/it, best loss: 1.4320762475430966]\n",
            "{'colsample_bytree': 0.65, 'eta': 0.07500000000000001, 'gamma': 0.55, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 581.0, 'subsample': 0.8500000000000001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeeEAS6WTDCe"
      },
      "source": [
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dvalid = xgb.DMatrix(X_test, label=y_test)\n",
        "model = xgb.train({'colsample_bytree': 0.65, \n",
        "                   'eta': 0.07500000000000001, \n",
        "                   'gamma': 0.55, \n",
        "                   'max_depth': 6, \n",
        "                   'min_child_weight': 6.0, \n",
        "                   'n_estimators': 581.0, \n",
        "                   'subsample': 0.8500000000000001,\n",
        "                   'objective': 'multi:softmax',\n",
        "                   'num_class': 5}, dtrain, 581)\n",
        "y_pred = model.predict(dvalid).astype(int)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uae4as3mTDCu",
        "outputId": "2ae589aa-fc4a-48b0-e454-677c63599a76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(classification_report(y_test, y_pred, zero_division=0))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.22      0.30        32\n",
            "           1       0.39      0.33      0.36        54\n",
            "           2       0.37      0.45      0.40        76\n",
            "           3       0.40      0.56      0.47        64\n",
            "           4       0.25      0.08      0.12        24\n",
            "\n",
            "    accuracy                           0.39       250\n",
            "   macro avg       0.38      0.33      0.33       250\n",
            "weighted avg       0.39      0.39      0.37       250\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-vPaGgMTDCy",
        "outputId": "70b2b2ea-64e6-49ec-f8a5-74f147e85039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import joblib\n",
        "model_output_path = os.path.join('/', 'drive', 'My Drive', 'data', 'processed', 'final-model.joblib')\n",
        "joblib.dump(model, model_output_path)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/drive/My Drive/data/processed/final-model.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}