{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug Severity Predictor for Mozilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I'll build a severity predictor for the [Mozilla project](https://www.mozilla.org/en-US/) that uses the description of a bug report stored a in [Bugzilla Tracking System](https://bugzilla.mozilla.org/home) to predict its severity. \n",
    "\n",
    "The severity in the Mozilla project indicates how severe the problem is – from blocker (\"application unusable\") to trivial (\"minor cosmetic issue\"). Also, this field can be used to indicate whether a bug is an enhancement request. In my project, I have considered five severity levels: **trivial(0)**, **minor(1)**, **major(2)**, **critical(3)**, and **blocker(4)**. I have ignored the default severity level (often **\"normal\"**) because this level is considered as a choice made by users when they are not sure about the correct severity level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below declares the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdLIqBsPTDBc",
    "outputId": "830417bc-b9b5-4438-f005-47b334356e39"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "\n",
    "#from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from predictive_modeling import load_tensors_data_fn, optimize_model_fn\n",
    "#from google.colab import drive\n",
    "#drive.mount('/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the tensor data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below load the features in tensor data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3_YrS8MZTDCI"
   },
   "outputs": [],
   "source": [
    "#tensors_input_path = os.path.join('/', 'drive', 'My Drive', 'data', 'processed')\n",
    "tensors_input_path = os.path.join('..', 'data', 'processed')\n",
    "X_train, y_train   = load_tensors_data_fn(os.path.join(tensors_input_path, 'mozilla_bug_report_train_data.pt'))\n",
    "X_test, y_test     = load_tensors_data_fn(os.path.join(tensors_input_path, 'mozilla_bug_report_test_data.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the predicting model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below gets the best parameters for XGBoost algorithm using Bayesian Optimization \n",
    "Method implemented in [Hyperopt](https://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ByIGD1xXTDCS",
    "outputId": "f15a51b3-dfad-45ec-8d22-2f550efe6a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [32:28<00:00, 194.81s/trial, best loss: 1.4197163827419281]\n"
     ]
    }
   ],
   "source": [
    "# getting the best parameters using optimize_model from local feature_engineering package.\n",
    "best_params=optimize_model_fn(X_train, X_test, y_train, y_test, max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      " {'colsample_bytree': 1.0, 'eta': 0.025, 'gamma': 0.55, 'max_depth': 12, 'min_child_weight': 2.0, 'n_estimators': 282.0, 'subsample': 0.8500000000000001}\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters:\\n', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below trains the XGBoost model with the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QeeEAS6WTDCe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:12:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "best_params['objective'] =  'multi:softmax'\n",
    "best_params['num_class'] = 5\n",
    "n_estimators = best_params['n_estimators'].astype(int)\n",
    "del best_params['n_estimators']\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "model = xgb.train(best_params, dtrain, n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below tests the XGBoost trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uae4as3mTDCu",
    "outputId": "596884a6-a5eb-4e8c-a943-a8ea1ae49342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.16      0.23        32\n",
      "           1       0.42      0.33      0.37        54\n",
      "           2       0.39      0.49      0.43        76\n",
      "           3       0.39      0.58      0.47        64\n",
      "           4       0.20      0.04      0.07        24\n",
      "\n",
      "    accuracy                           0.39       250\n",
      "   macro avg       0.36      0.32      0.31       250\n",
      "weighted avg       0.38      0.39      0.37       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(dvalid).astype(int)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the predicting model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below deploys the trained and tested XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "R-vPaGgMTDCy"
   },
   "outputs": [],
   "source": [
    "#import joblib\n",
    "model_output_path = os.path.join('..','data', 'model')\n",
    "if not os.path.exists(model_output_path):\n",
    "    os.makedirs(model_output_path)\n",
    "\n",
    "#model_output_path = os.path.join('/', 'drive', 'My Drive', 'data', 'processed', 'final-model.bin')\n",
    "model.save_model(os.path.join(model_output_path, 'final-model.bin'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
